# Daily

A place where I write public daily thoughts.

<h2 id="01-18-2023">
  <a href="#01-18-2023">18th January, 2023</a>
</h2>

One of things I learned from [The Missing Semester
course](/posts/2023-01-03/the-missing-semester-review) is jobs in the terminal.

I found it interesting to be able to background something, and bring it back. For instance
with React Native, I typically run the Metro server, however, I don't want to keep a terminal
pane open just for that, with "bg", "jobs", and "fg" command I can keep it in the background.

Do this: 

- Start Metro server in the background by doing: `yarn start &` or `nohup yarn start &`

> ps: You could also do `yarn start` then type `Ctrl-Z` to suspend that process
> and finally continue it in the background by doing `bg %<job_number>`, but it's
> easier to use the "&" shortcut at the end

- Bring it back when you need it: `fg`
- See all jobs in the background with: `jobs`

Even though I use Tmux, sometimes I still use these backgrounding tricks to not
need to switch my current context.


<h2 id="01-17-2023">
  <a href="#01-17-2023">17th January, 2023</a>
</h2>

Few quick learnings:

**Get the current file version in another branch**

Without changing branches, how do you get the version of file B on branch C?

`git show branch_c:file_b`

If you are using Vim and Vim Fugitive you can just do this within Vim.

**Changing 1000 files with Vim + Quickfix + cfdo**

Vim is quite powerful for file editing, I had the following work today:

Replaces all instances of `const SomeComp: Component<Props> = memo(...)` for `const SomeComp = memo<Props>(...)`

There some variations to the above, but that was the main part of it.

**How did I do it?**

1. Using Telescope grep files I found all instances of this and places it in Vim's Quickfix list.

2. Run your replacement command on each file

`cfdo %s/: Component<\(.*\)> =\n.*memo/ = memo<\1>/ge | %s/: Component<\(.*\)>.*memo/ = memo<\1>/ge | %s/: Component<\(.*\)>.*=.*\n.*\n.*memo/ = memo<\1>/ge | %s/import.*Component.*@core.*\n//ge | update | :bd`

**Some of the basics**

- "cfdo" will run the command on each file.
- the "| update" and "| :bd" at the end is for saving the file and lastly closing the buffer that was opened

_note that Vim will hang and have problems if you open 1000+ buffers, by default ":cfdo" will leave the buffer open if you modified it._

- I'm using the ":s" command to find instances of the Component type and replace it.

**Explanation of `%s/: Component<\(.*\)> =\n.*memo/ = memo<\1>/ge`**

"%s" will search entire file, works as "%s/match_some_pattern/replace_for_this_pattern/flags"
Note that I used "ge" as flags, "g" means global and "e" tells it to surpress errors.

The match is ": Component<\(.*\)> =\n.*memo" which is replaced by " = memo<\1>". Do note "\1" is referencing the captured group caught by the parenthesis in the matching pattern.

This was slightly complex but very powerful thing. Hope you find it useful. Tweet at me if you have any questions.

<h2 id="01-13-2023">
  <a href="#01-13-2023">13th January, 2023</a>
</h2>

Hey, happy Friday 13th! For some this is a spooky date.

Did you know you can't type a named function in TypeScript with an alias type?

A common pattern we have is to create a function type as follows:

`type someFn = (argOne: string, argTwo: number) => number`

The thing is we can't use that alias type `someFn` to type a named function.

Take `myOtherFn` that implements `someFn`:

```typescript
// I can use a variable defined with any type of function:
const myOtherFn: someFn = (argOne, argTwo) => 12; // OK
```

The above variable definition can contain any type of function, but if you did:

```typescript
// No way to type a named function like this with an alias type
function myOtherFn(argOne, argTwo) {
  return 12;
}
```

But why does this matter? Well, in some codebases using only named function can
be useful specially to get stacktraces of callbacks.

So how can you reuse the `someFn` type definition of your named functions?

The answer is you can't but you can compose your named function type definition by
using [`Parameters`](https://www.typescriptlang.org/docs/handbook/utility-types.html#parameterstype) and [`ReturnType`](https://www.typescriptlang.org/docs/handbook/utility-types.html#returntypetype) utilities from TypeScript

```typescript
// No way to type a named function like this with an alias type
function myOtherFn(...args: Parameters<someFn>): ReturnType<someFn> {
  const [argOne, argTwo] = args;
  return 12;
}
```

It's not clean and does require you to change how you consume the arguments but it is what it is.

Why do `(...args: Parameters<someFn>)` instead of `(argOne: Parameters<someFn>[0], argTwo: Parameters<someFn>[1])`?

Well, if you defined each argument, you would have to change this function
everytime `someFn` changed? Not a big deal, so up to you if you prefer it that
way.

<h2 id="01-12-2023">
  <a href="#01-12-2023">12th January, 2023</a>
</h2>

I almost logged out today without writing my daily dev.

Since I didn't think about what I wanted to write today, here is a glimpse of
what I'm working on, this is still incomplete:

```typescript
/*
 * The purpose of OnlyPrimitives is to disallow non-serializable values in navigation
 * params. We serialize navigation state for deeplinking navigation state restore.
 * */
export type DisallowedParam = "NON-PRIMITIVE PARAMS ARE NOT ALLOWED IN NAVIGATION";
export type Primitive = string | boolean | number | symbol | undefined | null;
export type OnlyPrimitives<TObj> = TObj extends Primitive
  ? TObj
  : TObj extends (infer TArray)[]
  ? OnlyPrimitives<TArray>[]
  : TObj extends (...args: unknown[]) => unknown
  ? DisallowedParam
  : TObj extends Record<string | number | symbol, unknown>
  ? {
      [key in keyof TObj]: OnlyPrimitives<TObj[key]>;
    }
  : TObj extends PreloadedQuery<OperationType, unknown>
  ? DisallowedParam
  : TObj;
```

In react-navigation, it is a bad idea to put non-serializable values in your
navigation params because we usually serialize your navigation state for to
restore a session or when we what to deeplink somewhere.

This OnlyPrimitives generic type takes a union of all screens Params and makes breaks
any param value that is a function or an instance of PrelaodedQuery.

The reason I'm breaking the type definition of only these two values is because these
are 100% the type of non-serializable values we are passing in the app I work with.

And checking for all non-primitives caused a few problems that included:
breaking union types; having false positives with places that did not include
proper types; and some other issues.

I'm still trying to figure out how to make this exactly as I want.

<h2 id="01-11-2023">
  <a href="#01-11-2023">11th January, 2023</a>
</h2>

While we wait for official ways from React to create our own Suspense APIs. How
could you create a Suspenseful resource plus why would you want to do this?

First, why do this? Well, the answer might be because useEffect is not an ideal
API for asynchronous operations. Second, by using this concept of a Suspenseful
Resource you could easily implement a "render-as-you-fetch" pattern. Third,
using Suspense for handling data loading and error states makes for a nice
component UI pattern, decoupling loading and error state from fetching.

_Before you proceed please be warned this is not based on React team's
recommendation and bound to break in future React versions, use it at your own
responsibility_.

**A Suspenseful Resource**

What if you could handle asynchronous data as a Resource that is either loading or loaded in memory:

```typescript
const MyDataComp = () => {
  const { data, refresh } = useResource(Resource);
  return (
    <>
      <p>Data is: {data}</p>
      <button onClick={refresh}>Reload</button>
    </>
  )
}

...

<Suspense fallback={<p>loading...</p>}>
  <MyDataComp />
</Suspense>
```

Well you can of can if you throw a Promise and keep it cached in memory:

```typescript
const fakeGetData = () =>
  new Promise((res) => setTimeout(() => res("ASYNC_REQUESTED_DATA"), 1000));

export const Resource = {
  data: null,
  promiseState: "pending",
  promise: undefined,
  load() {
    this.promise = new Promise((resolve) => {
      this.promiseState = "pending";

      fakeGetData()
        .then((data) => {
          this.data = data;
          this.promiseState = "fulfilled";
        })
        .catch((e) => {
          this.promiseState = "rejected";
          throw new Error(e);
        })
        .finally(() => {
          resolve();
        });
    });
  },
  read() {
    if (this.promiseState !== "pending") {
      return this.data;
    }

    if (!this.promise) {
      this.load();
    }

    throw this.promise;
  },
  reset() {
    this.promiseState = "pending";
    this.promise = undefined;
    this.data = null;
  },
};

const useResource = (resource) => {
  const [state, setState] = useState(0);
  const data = resource.read();
  return {
    data,
    refresh: () => {
      resource.reset();
      setState((e) => ++e);
    },
  };
};
```

I don't have time today, but you can turn this Resource into an abstract class
with reusable methods for you to implement other Resources without code
duplication. We also need to add proper type definitions. I'll try to improve it
during this week and post on my next daily.

[Full Codesandbox of the above code](https://codesandbox.io/s/suspense-resource-example-qvh8g9?file=/src/App.tsx)

<h2 id="01-10-2023">
  <a href="#01-10-2023">10th January, 2023</a>
</h2>

On another daily I wrote about a <a href="#09-23-2022">useOnUpdated</a> hook
which did not make use of useEffect and was more predictable. I have also
started using a useOnMount hook with similar characteristics.

**useOnMount**

```typescript
function useOnMount(cb: () => void) {
  const isNotMounted = useRef(true);

  if (isNotMounted.current) {
    isNotMounted.current = false;
    cb();
  }
}
```

You could abstract just the clean up phase:

```typescript
function useCleanUpOnUnmount(cb: () => void) {
  return useEffect(() => () => cb(), []);
}
```

**But why do this?**

Narrowing down an API interface to do a single thing makes it more predictable.

Predictable APIs are easier to maintain and use. The `useEffect` API can do too many things making it bug prone.

<h2 id="01-09-2023">
  <a href="#01-09-2023">9th January, 2023</a>
</h2>

Notes on memoizing callbacks within callbacks in React plus a personal preference of using `React.ComponentProps<typeof YourComponent>` to type drilled down props.

**Memoizing callbacks within callbacks**

Agree with it or not, with React hooks, memoization became the default behavior many teams adopt with React.

Memoizing values within callbacks is not obvious when the callback needs to return a component.

Callbacks that return a component include:

1. List components like React Native's FlatList.
2. Any component implementing [Function as a Child Component](https://reactpatterns.js.org/docs/function-as-child-component/) pattern. ps: please don't do this anymore.

So for instance, if you want to memoize map's callback here:

```typescript
const renderItem = useCallback(({ item: row }) => {
  return (
    <HStack gap={2} spacingBottom={2} flexShrink={1}>
      {(row as NftsListItemProps[]).map((rowItem) => (
        <NftsListItem key={rowItem.id} {...rowItem} />
      ))}
    </HStack>
  );
}, []);
```

You would need to extract that as a component itself and do memoization at that level like:

```typescript
type NftsProps = { nfts: NftsListProps["data"] };
function NftList({ nfts }: NftsProps) {
  const list = useMemo(() => {
    return nfts.map((rowItem) => (
      <NftsListItem key={rowItem.id} {...rowItem} />
    ));
  }, [nfts]);

  return <>{list}</>;
}

// renderItem is within a component.
const renderItem = useCallback(
  ({ item: row }: { item: NftsListProps["data"] }) => {
    return (
      <HStack gap={2} spacingBottom={2} flexShrink={1}>
        <NftList nfts={row} />
      </HStack>
    );
  },
  []
);
```

So the lesson is to simply restructure the component and push down the logic to a component layer.

**Using ComponentProps**

One thing you will notice in the above example is the usage of `NftsListProps["data"]`. This is done simply because that type definition is within the same file.

But what if you are in another file consuming a component called `NftList` and you want to enforce another value to match a prop that `NftList` takes?

The typicaly solution often is importing `NftList`'s prop type definition like: `import type { NftListProps } from 'w.e';`.

However, did you know React has a helper called `ComponentProps`?

`import type { ComponentProps } from 'react';`

With `ComponentProps` you can do `type myData = ComponentProps<typeof NftList>['someFieldWithinNftListProps'];`.

I prefer this pattern because:

1. It couples the type definition with the Component props definition
2. You have a single import, the component.
3. Changes to the component props automatically synchronizes with the consumers.

<h2 id="01-06-2023">
  <a href="#01-06-2023">6th January, 2023</a>
</h2>

Today I spent time wrapping my head around Relay.js' APIs for query preloading. Below are some of my notes, I won't explain each of these APIs, if you are curious read [Relay.js' documentation](https://relay.dev/docs/api-reference).

Query preloading is an way for you to implement both preloading mechanism and also **"render-as-you-fetch"** approach.

[According to Relay.js' docs](https://relay.dev/docs/api-reference/use-preloaded-query/), the right way to do this is to use a combination of two hooks: **useQueryLoader** and **usePreloadedQuery**.

However, by default Relay uses a cache strategy called **"store-or-network"** which will only fetch the data if not available in its in-memory store. This allows you to use a combination of useQueryLoader and useLazyLoadQuery for a simple preloading strategy that does not include smart in-flight request reuse.

The thing is, usePreloadedQuery is not very developer ergonomic. It requires a bit of an imperative management of the request by calling a query laoder with the correct variables even when it goes stale.

Essentially usePreloadedQuery is a reader API that reads from a preloaded request reference often called **queryReference**.

**Points about using loadQuery + useLazyLoadQuery:**

- ❌ No request in-flight mechanism.
- ❌ useLazyLoadQuery without loadQuery is render-then-fetch.
- ✅ Easier to reason. Simply call loadQuery.
- ✅ useLazyLoadQuery refreshes on input changes.
- ❌ Does not do "render-as-you-fetch", loadQuery must fully resolved before mounting a useLazyLoadQuery.

**Points to using loadQuery + usePreloadedQuery:**

- ✅ preloaded request is reused.
- ✅ fully compatible with "render-as-you-fetch" approach.
- ❌ Must share queryReference
- ❌ Not easy to reason about due to our lack of pattern (can't use navigation params in React Native)
- ❌ usePreloadedQuery does not take variables, on input change you must imperatively call loadQuery again.

**What about the EntryPoint API?**

It's still a bit early to reason about the EntryPoint API. Relay doc's are incomplete. From the examples existent in the relay-examples repo we can derive the following information:

The API includes a way to not only preload a query but also its counterpart JavaScript module. The preloading of the counterpart module makes sense for lazy loading the JavaScript code related to the screen that will use the usePreloadedQuery.

Based on the TodoApp in the relay-examples you can see:

- [Place where the preload happens using loadEntryPoint](https://github.com/relayjs/relay-examples/blob/8cd2a13057304abb3be6866ea794875d09f0a4ee/todo/js/app.js#L51-L58)
- [Where the EntryPointContainer gets rendered](https://github.com/relayjs/relay-examples/blob/main/todo/js/app.js#L63)
- [A EntryPoint component definition.](https://github.com/relayjs/relay-examples/blob/main/todo/js/entrypoints/TodoApp.entrypoint.js#L10-L33)
- [TodoApp - the underlying component that gets lazily requested](https://github.com/relayjs/relay-examples/blob/main/todo/js/components/TodoApp.js#L17-L27)

From analyzing that code, we can say that the EntryPoint API introduces an extra feature to the loadQuery + usePreloadedQuery strategy, that is the ability to lazily load the JavaScript resources related to that preloaded screen - see this snippet of where that happens.

<h2 id="01-05-2023">
  <a href="#01-05-2023">5th January, 2023</a>
</h2>

This week I am working on a script that finds if we have any unused NPM dependencies. I plan on writing a separate post solely on how to do that, but let me highlight some interesting commands I learned while doing this.

**Node.js path**

Node.js' path module has a few useful methods you can use like `path.join` and `path.basename`.

- You can join two paths using `path.join('/src/module', '/more')`. This returns 'src/module/more'.

- `path.basename` returns the name of the file in a path.

Example: `path.basename('/src/module/package.json') // returns 'package.json' `

There are more, check out [path's documentation](https://nodejs.org/api/path.html).

**Git grep & rev-parse & ls-files**

Git has some awesome commands for you to find and search files.

Some examples:

- Find all package.json files in a project (common in Monorepos):

`git ls-files --full-name ':/**/package.json'`

- Find where the root of your Git project lives:

`git rev-parse --show-toplevel`

- Search some element within somes files

In this case I'm looking for any file that has ModuleA imported or required from in a given folder.

`git grep -e "from 'ModuleA" --or -e "require('ModuleA -- path/to/folder`

<h2 id="01-04-2023">
  <a href="#01-04-2023">4th January, 2023</a>
</h2>

I figured out the git grep limitation I ran into. Yesterday I wanted to do multiline Regex matching and I failed to figure it out. Today I [re-read Git docs on git grep](https://git-scm.com/docs/git-grep) and learned a bit more.

I wanted to find out if I have a given import happening in my code. Let's say I am interested if relay-test-utils is imported anywhere.

This can be done by:

`git grep --all-match -e import -e from -e relay-test-utils -- '*.ts' '*.tsx'`

- '--all-match' will extend the multiple matches to the entire file.
- '-e' allows for you to create multiple string matches as I have.
- The `-- '*.ts' '*.tsx'` tells Git's pathspec which files to consider.

[This is a good reference](https://css-tricks.com/git-pathspecs-and-how-to-use-them/) on the pathspec.

[This other blogpost](https://irian.to/blogs/learn-git-grep-to-boost-your-command-line-search/) was also very helpful. Tomorrow I will write a bullet list of some advanced commands using git grep plus git rev-list.

<h2 id="01-03-2023">
  <a href="#01-03-2023">3rd January, 2023</a>
</h2>

Happy new year!

As typical of every year, with renewed hopes and goals here I am with the goal of writing my dailies on every workday.

Quick learnings:

**Vim's :normal command**

I recently learned about [`:normal` command in Vim](https://learnvimscriptthehardway.stevelosh.com/chapters/29.html)

Try the following to add "-" on everyline of the highlighted text in Vim:

1. Highlight text in visual mode
2. Then type `:norm i-`

The above tells Vim to go into insert mode and types "-" to everyline of the highlighted text.

I found this so powerful.

**git grep's limitation**

Git grep is super fast but it sucks that it doesn't support multiline matching. Like for instance, I would like
to match a Regex as follow `/import.*from.*somelib/` but this won't work when you have imports formatted into
multiple lines.

It seems that this should work:

`git grep --all-match -e 'import' -e 'from.*somelib'`

But it does not. I was hoping to run this in a Linux machine thus I don't have access to fancy new tools like Ripgrep. If you know how to do this with `git grep` let me know.

<h2 id="12-13-2022">
  <a href="#12-13-2022">13th December, 2022</a>
</h2>

And I am back, as you can see I have not written since 18th October, life has not been very motivating.

Quick note on an interesting way to explore different directories in Vim/Neovim.

**Use case:** how can I change to a differrent directory, let's say a node_module dir, while in Vim to search and explore that project, while not losing my project directory scope.

The way I am doing this is with a combination of tabs and `:tcd` (change directory command for a tab scope, see `:h tcd`).

**Flow goes as:**

1. I am in /my_project_dir
2. I want to explore /my_project_dir/node_modules/react
3. To not lose my current context, I create a new tab by running `:tabe`
4. In this new tab, I `:lcd node_modules/react`
5. Now I can do whatever I like in the react directory such as search for code.
6. To change back I switch tabs with `:tabp` or `:tabn`

**Last notes:**

I tend to prefer typing out commands as full instead of using shortcuts. This is part of my minimalistic approach.

_Lastly, why is this useful?_

I often need to search for code in different directories. Using something like Fzf will only search within your project scope and it also ignores files that are part of your .gitignore. So to properly search within `node_modules/react` I need to change Vim's current directory to that folder.

Doing this flow also enables me to narrow down searches within some directories.

I hope you find this useful too.

<h2 id="10-18-2022">
  <a href="#10-18-2022">18th October, 2022</a>
</h2>

A few notes about the recent rant against React hooks.

I was thinking how it feels like all of the issues with modern React with hooks stems from the fact that someone decided to rely on a construct not supported by JavaScript - persistent function closures.

What I mean here is hooks introduce a way to persist a closure within a function. It expands the natural lifetime of a function in JavaScript. And thinking about it makes me wonder why would someone want this rather than just a fetiche for using functions? I couldn’t think of a reason of my own right now, maybe succinctness? not sure.

This sole idea required React Core team to introduce hooks. The explanation of how hooks work feels more like a language construct, specially how magical it is since it defies how the JavaScript language works.

Note that I am not a PL researcher to understand where these ideas came from.

Of course in hindsight it is easy to spot this issue and this makes me think that when the idea was presented it either a) was very convincing, possibly because the presenter was very eloquent and smart or b) no one dared push against the idea due to the author being a senior important figure in the team. Note that I do not know who had the original idea, so take this as purely speculative.

Futher thoughts in hindsight, it seems like not a good idea to introduce such large changes to an established framework such as React was at the time. Second, React Hooks didn’t really introduce any new features but rather just a second alternative to do most of the same thing with less code.

Where does this leave us? Well, in the same place. I do not intend to propose an alternative, for me React Native made React so beneficial overall for teams bulding for Web and Mobile apps that the pros easily outweighs the cons here. I do hope that these recent writings on the issues with React instigate curiosity and motivation for the React team to think of how they can further improve React as a framework.

<h2 id="10-08-2022">
  <a href="#10-08-2022">8th October, 2022</a>
</h2>

Still on a vacation.

Rencetly, While I was thinking about the retry mechanism on Relay I realized how this could be solved purely at the Suspense level. Relay makes use of Suspense to a) trigger data requests and b) handle loading and error boundaries. This made me realize that we could retry a failed request by re-mounting that given component. I wrote the following [blogpost to POC this idea](/posts/2022-10-03/retriable-suspense-wrapper).

<h2 id="09-29-2022">
  <a href="#09-29-2022">29th September, 2022</a>
</h2>

Hey, I am on vacation but since I on a writing streak (10 days now) I'm going to try to write my dailies until I run out of ideas.

A little bit about wy we are having issues with Relay's lack of a retry mechanism.

At work we are trying to improve error handling overall. The goal is to stop showing users full screen errors. While initially you would think that the easy solution is to simply stop having errors, that my friend is not possible.

Services has some expected error rate. I have seen services with a 4% error rate for every request - this forces the client to be obliged to deal with them.

Our strategy to improve error handling is to push it down to the leaf components instead of root screen wrappers.

_**let me explain the app I am working...**_

Typically when you load a screen you load all of your data upfront in a single place. However, with React and GraphQL (Relay) it is known to be a better pattern to colocate data requests alongside their consuming components. Thus with a typical GraphQL Relay app, data is not requested within the root of the screen, further with data masking - a Relay feature, the root parent component is not even aware of its child's data requirements.

_**a bit more about Relay's GraphQL pattern...**_

Why colocate the data requests and use data masking? This decouples the components and makes them easier to be refactored, This sets a limited impact boundary for your components.

_**back to error handling...**_

With colocated data requests/requirements you can also handle the loading state and error at the component level, making for instance Screen B to render even if one of its child broke.

Our goal is to handle breakage at each component level, gracefully handling the error and giving the user the ability to retry it.

But, with Relay, today you need to refetch the entire query when a fragment (a child component's data requirements in GraphQL) fails. This is why I am looking into a better way to retry a fragment query.

<h2 id="09-28-2022">
  <a href="#09-28-2022">28th September, 2022</a>
</h2>

On a side project I have I decided to use Amplify. A few months in this and I regret my decision. Here is a list of why:

0. Quick to get started, slow to do anything complex

As probably most low code or no-code solutions. It's quick to get you started, but the more you need to customize it the more it slows you down. Below I list a few problems I ran into with Amplify that will backup this argument.

1. Amplify abstracts away many services within Amazon.

Any issues within these services you need domain knowledge of them to figure it out. Not so bad, but has a high a learning cost. Expect to learn CloudFormation, DynamoDB, Lmabda services, IAM policies, and more.

2. Amplify's GraphQL layer is limiting

Examples of this include:

- filtering only works at the parent query and not its nested items;
- its many-to-many relationships are a bit limited and you will find yourself creating many global secondary indexes (GSI) to make any real world query;
- also creating and updating GSIs are brittle, you can't update a GSI, you have to delete it first, fully deploy, then recreate it with your changed attributes;

3. Deploying is slow

With Amplify you have a GraphQL schema that dictates the structure of your database. Changing the schema then publishing it requires you to deploy your services through `yarn amplify push` which takes about 20-30 minutes.

4. Auth layer doesn't integrate well with the GraphQL layer

If GraphQL is my querying layer and I want to get user information plus data related to that user you would think this should all come from GraphQL right? Well, for Amplify creators it was not ¯\_(ツ)\_/¯.

Would I recommend Amplify to anyone? Yes, do you have a clearly constrained case where you need a data store for non-nested data and auth integrated? Amplify could be a solution here because of its comes with an Auth UI out of the box plus some other UI components for easy integration.

ps: Last paragraph it is me being nice.

<h2 id="09-27-2022">
  <a href="#09-27-2022">27th September, 2022</a>
</h2>

Not very inspired today. I am always curious in ways of improving my Vim experience. Today I found out there is a nice way to edit commands you write within Vim.

The way command mode works in Vim is as follow:

1. You execute some command, let's say you type `:echo hello` within Vim.

2. If you want to repeat that command you always type `@:`.

3. Editing commands in normal mode

But if you want to edit any of the previous command you can type `:` then press `<ctrl>-f` to enter "command mode" which puts you in normal mode but with all your previous commands in the buffer. You can edit any of the lines and pressing enter on a line executes the command.

Why do I like this so much?

I typically repeat commands with some variations and having the ability to quickly edit a past command like that with Vim's normal and insert mode makes this much easier.

[Stackoverflow about command mode.](https://stackoverflow.com/questions/39168379/vim-how-to-move-one-word-left-in-command-mode)

**Small rant about Relay**

Relay is missing a retry mechanism for its hooks. I will likely implement one. But it surprises me that it doesn't have one.

<h2 id="09-26-2022">
  <a href="#09-26-2022">26th September, 2022</a>
</h2>

I'm becoming more and more convinced to rely less on IDE features and instead leverage lower level commands using the terminal. Why do that? because your IDE will always be constrained by its UI, even with Vim/Neovim. In the terminal you can compose different commands and get different results specific to your desire, the limit boundary is way bigger than an UI.

Here are some flows you do in an IDE that you can do with a terminal:

**Search for file**

`find src -type file -name "Root*"`

_find in directory src a file named Root plus whatever._

**Find matches of a pattern**

`rg -e "Bugsnag\.notify\("`

**Get a list of all files that has the matching pattern**

`rg -e "Bugsnag\.notify\(" -c`

**Find how many total matches a given pattern had**

`rg -e "Bugsnag\.notify\(" | wc -l`

I'll be reviewing more and more of these commands as I improve my arsenal.

<h2 id="09-25-2022">
  <a href="#09-25-2022">25th September, 2022</a>
</h2>

A few months ago I integrated Amplify into a [Remix.run](https://remix.run/) app and today I [saw an example that took a different approach by using AppSync with ApolloGraphQL](https://github.com/aaronksaunders/amplify-remix-todos-1).

I felt that approach was a bit overkill. The only trick to get [Amplify's `withSSRContext`](https://docs.amplify.aws/lib/ssr/q/platform/js/) working is to properly map Remix's request object to the one `withSSRContext` expects, which I do as follow:

```javascript
const client = withSSRContext({
  req: { headers: { cookie: args.request.headers.get("cookie") } },
});
```

The above code would be in a Remix loader function.

<h2 id="09-24-2022">
  <a href="#09-24-2022">24th September, 2022</a>
</h2>

Today I spent some time trying to figure out why Amplify was stuck on this `Resource is not in the state stackUpdateComplete` error.

**Error:**

```cli
✖ An error occurred when pushing the resources to the cloud
🛑 An error occurred during the push operation: /
["Index: 0 State: {\"deploy\":\"waitingForDeployment\"} Message: Resource is not in the state stackUpdateComplete"]
⚠️ Review the Amplify CLI troubleshooting guide for potential next steps: https://docs.amplify.aws/cli/project/troubleshooting/
```

At first, without much AWS experience this kind of error is quite bizarre. Well, after a lots of digging you start to learn the following:

1. Amplify automates creation of resources
2. This automation is done by CloudFormation's stacks
3. The "resource is not in the state stackUpdateComplete" refers to a stack resource in CloudFormation.

After understanding the following I finally started looking in the right place. CloudFormation's stack display exactly which stack had an error. In my case, it was some DynamoDB table that was stuck.

A common issue with CloudFormation is configuration drift - this is when your automated configs are different from the actual resources because someone changed something through the UI instead of your config code (in my case these configs are managed by Amplify).

The drift issue is so common [they have an entire section/UI dedicated to identifying such issues](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/detect-drift-stack.html).

Once I got to the drift problem I was able to rapidly identified one of the resources that drifted. But how do I revert this issue?

You can resolve the drift by either:

1. Manually reverting the change you did via UI
2. Updating the CloudFormation's stack template (I did this via its change set feature).

I chose the second option since I couldn't find the UI option that triggered the initial change.

Another tip is to look for the actual failing resource within the stacks, you are likely to find a log there that can help. For my case we were having the [GSI error issue described here](https://stackoverflow.com/questions/62976032/how-can-i-update-dynamodb-gsi-when-projection-type-is-changed).

<h2 id="09-23-2022">
  <a href="#09-23-2022">23rd September, 2022</a>
</h2>

In big tech companies, nothing will get built if it moves no key result (OKR). Today I heard someone say I'm not sure we want to prioritize a given task simply because there is no KR tracking given result.

---

**A better useEffect** for when you need to react to a state change.

```typescript
import { useRef } from "react";

const useOnUpdated = (cb: () => void, dependency: any) => {
  const last = useRef<any>(undefined);

  if (dependency !== last.current) {
    last.current = dependency;
    cb();
  }
};
```

But why?

Well, useEffect is often called more times than you expect. This hooks adds simplicity and predictability over behavior. Plus, the single dependency is intentional to make sure we are only doing one thing instead of many things - you would prefer multiple useOnUpdated which will result in easier to maitain code.

<h2 id="09-22-2022">
  <a href="#09-22-2022">22nd September, 2022</a>
</h2>

There are days we spin our wheels and accomplish almost nothing.

Today was a day I had to remind myself how to find specific files and search for certain patterns. Over time I am more and more convinced that it is better to learn the lower level commands on the CLI than to rely on any IDE feature for common search and edit file or file contents.

How do you find an apk file within your directory?

`find . -type file -name "*.apk"`

How do you find a file that imports a module named "config" which is imported from "mobule-b"?

Turns out "config" is quite a common word and "mobule-b" might be imported 100s of times.

The following can do that for you:  
`rg -U 'import.*config.*mobule-b'`

The trick here is enabling multiline grep with the `-U` option.

<h2 id="09-21-2022">
  <a href="#09-21-2022">21th September, 2022</a>
</h2>

Today was a long day. I had a nice opportunity to improve React Native's horizontal scroll view. I found an edge case where the snap to animation was very slow/sluggish. [See PR here](https://github.com/facebook/react-native/pull/34756).

This was part of yesterday's work and why I had to run my app by compiling react-native's source.

I wrote a [TIL about git diff's file filtering feature](/posts/2022-09-21/til-git-diff-file-filter).

<h2 id="09-20-2022">
  <a href="#09-20-2022">20th September, 2022</a>
</h2>

Today I had to patch react-native's source code to fix an Android issue.

Turns out by default react-native only compiles its native code when the new Fabric architecture is enabled else it uses a prebuilt lib.

To turn on compilation of react-native's source code you need to remove the following if checks in [build.gradle](https://github.com/facebook/react-native/blob/bcb58089c4723a005326cb7a8b44e349c6a9a451/template/android/app/build.gradle) and [settings.gradle](https://github.com/facebook/react-native/blob/bcb58089c4723a005326cb7a8b44e349c6a9a451/template/android/settings.gradle):

```gradle
M src/packages/app/android/app/build.gradle
@@ -423,7 +423,7 @@ dependencies {
     implementation 'com.google.android.play:core:1.8.0'
 }

-if (isNewArchitectureEnabled()) {
+// if (isNewArchitectureEnabled()) {
     // If new architecture is enabled, we let you build RN from source
     // Otherwise we fallback to a prebuilt .aar bundled in the NPM package.
     // This will be applied to all the imported transtitive dependency.
@@ -437,7 +437,7 @@ if (isNewArchitectureEnabled()) {
             //         .because("On New Architecture we're building Hermes from source")
         }
     }
-}
+// }

 apply from: file("$nodeModulesPath/@react-native-community/cli-platform-android/native_modules.gradle"); applyNativeModulesAppBuildGradle(project)
```

```gradle
M src/packages/app/android/settings.gradle
@@ -7,11 +7,12 @@ apply from: file("$nodeModulesPath/@react-native-community/cli-platform-android/
 include ':app'
 includeBuild("$nodeModulesPath/react-native-gradle-plugin")

+include(":ReactAndroid")
+project(":ReactAndroid").projectDir = file("$nodeModulesPath/react-native/ReactAndroid")
+
 if (settings.hasProperty("newArchEnabled") && settings.newArchEnabled == "true") {
-    include(":ReactAndroid")
-    project(":ReactAndroid").projectDir = file("$nodeModulesPath/react-native/ReactAndroid")
-    include(":ReactAndroid:hermes-engine")
-    project(":ReactAndroid:hermes-engine").projectDir = file("$nodeModulesPath/react-native/ReactAndroid/hermes-engine")
+	include(":ReactAndroid:hermes-engine")
+	project(":ReactAndroid:hermes-engine").projectDir = file("$nodeModulesPath/react-native/ReactAndroid/hermes-engine")
 }
```

Once I compiled its source code I could debug it with Android Studio and find where to fix the issue. I'll post about the issue on another day.

<h2 id="09-19-2022">
  <a href="#09-19-2022">19th September, 2022</a>
</h2>

Hello world. It was on my TODO list that I was going to get this done. So, I'm done = ).

But, here are some random thoughts:

**1) There are no reliable dev environments in the finance industry**

I've been working in the Crypto space for a year now and this is a huge pain point for us. Researching about the topic I learned it is a shared pain due to the number of external integrations with legacy bank systems. Plus, it is hard to maintain fakers for every API you have.

**2) Handling app errors gracefully**

This has been a recorrent topic at work. The app grew and an initial pattern implemented in the early days of the app is becoming bad user experience - full screen errors.

Over the years I noticed a few patterns emerge while building apps. The first is fully neglecting errors and letting apps just crash. The second pattern is typically a solution for the first which is a generic error screen that serves as a catch all, this is the stage where the current app I work with is at. And perhaps the last stage is pushing error handling closer to the leaf UI elements that cause them in the UI tree with addition to proper reaction mechanisms such as retries.

In hingsight it feels like if we instead started backwards - that is handling errors only at the leaf nodes before going higher up the UI tree, this could make it easier over time to deliver a better UX.

But why doesn't that happen?

I don't know the answer. But, I would think that the clear lack of paved road in this area makes for less experienced developers to simply neglect error handling as a whole.
